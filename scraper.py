import json
import os
import time
import random
import pandas as pd
from curl_cffi import requests
from datetime import datetime

# ‡ßß. ‡¶Ö‡¶ü‡ßã ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶∂‡¶® (Data tracking ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø)
os.makedirs('data', exist_ok=True)
os.makedirs('reports', exist_ok=True)

class EnterpriseScraper:
    def __init__(self):
        self.target_url = "https://draw.ar-lottery01.com/WinGo/WinGo_30S/GetHistoryIssuePage.json"
        self.db_path = "data/wing_history.json"
        self.report_path = "reports/market_analysis.md"
        # ‡¶∂‡¶ï‡ßç‡¶§‡¶ø‡¶∂‡¶æ‡¶≤‡ßÄ ‡¶¨‡ßç‡¶∞‡¶æ‡¶â‡¶ú‡¶æ‡¶∞ ‡¶´‡¶ø‡¶ô‡ßç‡¶ó‡¶æ‡¶∞‡¶™‡ßç‡¶∞‡¶ø‡¶®‡ßç‡¶ü ‡¶™‡ßç‡¶∞‡ßã‡¶´‡¶æ‡¶á‡¶≤
        self.profiles = ["chrome110", "chrome120", "edge101", "safari_ios_16_0"]

    def get_headers(self):
        # ‡¶∞‡¶ø‡ßü‡ßá‡¶≤ ‡¶π‡¶ø‡¶â‡¶Æ‡ßç‡¶Ø‡¶æ‡¶® ‡¶¨‡ßç‡¶∞‡¶æ‡¶â‡¶ú‡¶æ‡¶∞ ‡¶π‡ßá‡¶°‡¶æ‡¶∞
        return {
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "en-US,en;q=0.9",
            "Content-Type": "application/json;charset=UTF-8",
            "Origin": "https://draw.ar-lottery01.com",
            "Referer": "https://draw.ar-lottery01.com/",
            "User-Agent": f"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{random.randint(115, 122)}.0.0.0 Safari/537.36",
            "X-Requested-With": "XMLHttpRequest"
        }

    def fetch_with_retry(self):
        payload = {"pageIndex": 1, "pageSize": 50, "type": 30}
        
        # ‡¶¨‡ßç‡¶≤‡¶ï‡¶ø‡¶Ç ‡¶è‡ßú‡¶æ‡¶§‡ßá ‡ß© ‡¶¨‡¶æ‡¶∞ ‡¶ü‡ßç‡¶∞‡¶æ‡¶á ‡¶ï‡¶∞‡¶¨‡ßá
        for attempt in range(3):
            try:
                print(f"[{datetime.now()}] Attempt {attempt+1}: Fetching data...")
                with requests.Session() as s:
                    # ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá ‡¶ï‡ßÅ‡¶ï‡¶ø ‡¶®‡ßá‡¶ì‡ßü‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶π‡ßã‡¶Æ‡¶™‡ßá‡¶ú ‡¶≠‡¶ø‡¶ú‡¶ø‡¶ü
                    s.get("https://draw.ar-lottery01.com/", impersonate=random.choice(self.profiles))
                    time.sleep(random.uniform(2, 5))
                    
                    response = s.post(
                        self.target_url,
                        json=payload,
                        headers=self.get_headers(),
                        impersonate=random.choice(self.profiles),
                        timeout=30
                    )

                if response.status_code == 200:
                    data = response.json()
                    if 'data' in data and 'list' in data['data']:
                        return data['data']['list']
                
                print(f"Warning: Status {response.status_code}. Retrying...")
                time.sleep(5)
            except Exception as e:
                print(f"Retry {attempt+1} failed: {e}")
        return None

    def save_data(self, new_items):
        if not new_items:
            print("CRITICAL: Failed to bypass protection. No data received.")
            return

        # ‡¶Ü‡¶ó‡ßá‡¶∞ ‡¶°‡¶æ‡¶ü‡¶æ ‡¶≤‡ßã‡¶°
        history = []
        if os.path.exists(self.db_path):
            try:
                with open(self.db_path, "r", encoding="utf-8") as f:
                    history = json.load(f)
            except: history = []

        # ‡¶°‡ßÅ‡¶™‡ßç‡¶≤‡¶ø‡¶ï‡ßá‡¶ü ‡¶∞‡¶ø‡¶Æ‡ßÅ‡¶≠ ‡¶ï‡¶∞‡ßá ‡¶®‡¶§‡ßÅ‡¶® ‡¶°‡¶æ‡¶ü‡¶æ ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶°
        existing_ids = {str(item.get('issueNumber')) for item in history}
        added = 0
        for item in new_items:
            if str(item.get('issueNumber')) not in existing_ids:
                history.append(item)
                added += 1

        if added == 0:
            print("Status: Database is already up to date.")
            return

        # ‡¶≤‡ßá‡¶ü‡ßá‡¶∏‡ßç‡¶ü ‡ß®‡ß¶,‡ß¶‡ß¶‡ß¶ ‡¶°‡¶æ‡¶ü‡¶æ ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶∏‡ßá‡¶≠ ‡¶∞‡¶æ‡¶ñ‡¶¨‡ßá
        history = sorted(history, key=lambda x: str(x.get('issueNumber')), reverse=True)[:20000]

        with open(self.db_path, "w", encoding="utf-8") as f:
            json.dump(history, f, indent=4, ensure_ascii=False)

        print(f"Success: {added} new records saved to data/ folder.")
        self.generate_report(history)

    def generate_report(self, history):
        df = pd.DataFrame(history)
        latest_table = df.head(15)[['issueNumber', 'number', 'colour']].to_markdown(index=False)
        
        report_content = f"""
# üöÄ Wingo Enterprise Intelligence (2026)
**Last Sync Time:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

### üìä Live Market Data (Last 15 Draws)
{latest_table}

---
*Generated by Market-Analyzer-Bot. Data stored in data/ folder.*
"""
        with open(self.report_path, "w", encoding="utf-8") as f:
            f.write(report_content)

if __name__ == "__main__":
    # ‡¶π‡¶ø‡¶â‡¶Æ‡ßç‡¶Ø‡¶æ‡¶® ‡¶∏‡¶ø‡¶Æ‡ßÅ‡¶≤‡ßá‡¶∂‡¶® ‡¶°‡¶ø‡¶≤‡ßá
    time.sleep(random.uniform(5, 10))
    bot = EnterpriseScraper()
    final_data = bot.fetch_with_retry()
    bot.save_data(final_data)
        
